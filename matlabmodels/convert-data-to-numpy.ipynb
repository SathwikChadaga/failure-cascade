{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import os\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0907558",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loadScaleList = ['random']\n",
    "loadScaleList = ['1.00', '1.10', '1.20', '1.30', '1.40', '1.50', '1.60', '1.70', '1.80', '1.90', '2.00']\n",
    "N_nodes = 89\n",
    "numSamples = 10000\n",
    "processCascadeData = True\n",
    "processInfluenceModelWeights = True\n",
    "\n",
    "caseName = 'IEEE' + str(N_nodes)\n",
    "numSamplesFolderName = 'samples' + str(numSamples) + '/'\n",
    "numSamplesTrain = int(np.round(0.9*numSamples))\n",
    "numSamplesTest = numSamples - numSamplesTrain\n",
    "M_linesDict = {89:206,118:179,1354:1710}\n",
    "M_lines = M_linesDict[N_nodes]\n",
    "numNodeFeatures = 2\n",
    "numEdgeFeatures = 2\n",
    "\n",
    "for loadScale in loadScaleList:\n",
    "    dataDirectory = './data/'\n",
    "    dataDirectory = dataDirectory + 'dc/'\n",
    "    dataDirectory = dataDirectory + caseName + '/'\n",
    "    linksetdataDirectory = dataDirectory\n",
    "\n",
    "    dataDirectory = dataDirectory + 'load' + loadScale + 'gen' + loadScale + '/'\n",
    "    dataDirectory = dataDirectory + numSamplesFolderName\n",
    "    print(dataDirectory)\n",
    "    if(processCascadeData): prepareOneShotData()\n",
    "    if(processInfluenceModelWeights): prepareInfluenceModelData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d158c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readVariablePairs(fileName, variable1, variable2):\n",
    "    variable1 = scipy.io.loadmat(fileName)[variable1].T\n",
    "    variable2 = scipy.io.loadmat(fileName)[variable2].T\n",
    "    currData = np.stack((variable1, variable2), axis=-1)\n",
    "    return currData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readOneShotData():\n",
    "    nodeData = np.zeros((numSamples, N_nodes, numNodeFeatures))\n",
    "    edgeData = np.zeros((numSamples, M_lines, numEdgeFeatures))\n",
    "    for ii in trange(numSamples):\n",
    "        fileName =  dataDirectory + 'data_sample' + str(ii) + '.mat'\n",
    "        \n",
    "        # read node data\n",
    "        currNodeData = readVariablePairs(fileName, 'powerConsumeData', 'powerSuppliedData')\n",
    "        nodeData[ii,:,:] = currNodeData[0,:,:]\n",
    "\n",
    "        # read edge data\n",
    "        currEdgeData = readVariablePairs(fileName, 'activeLinesData', 'powerFlowData')\n",
    "\n",
    "        edgeData[ii,:,0] = currEdgeData[0,:,0]\n",
    "\n",
    "        a = np.sum(currEdgeData[:,:,0], axis=0)\n",
    "        a[a == np.max(a)] = -1\n",
    "        edgeData[ii,:,1] = a\n",
    "        \n",
    "    return nodeData, edgeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5526fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareOneShotData():\n",
    "    # read node edge data\n",
    "    nodeData, edgeData = readOneShotData()\n",
    "\n",
    "    nodeDataTrain = nodeData[:numSamplesTrain,:,:]\n",
    "    edgeDataTrain = edgeData[:numSamplesTrain,:,:]\n",
    "    nodeDataTest = nodeData[numSamplesTrain:,:,:]\n",
    "    edgeDataTest = edgeData[numSamplesTrain:,:,:]\n",
    "\n",
    "    print(nodeDataTrain.shape)\n",
    "    print(edgeDataTrain.shape)\n",
    "    print(nodeDataTest.shape)\n",
    "    print(edgeDataTest.shape)\n",
    "\n",
    "    # read linkset data\n",
    "    linksetFileLocation = linksetdataDirectory  + 'linksetAndCapacity' + str(caseName) \n",
    "    linksetFileLocation = linksetFileLocation + 'load' + loadScale + 'gen' + loadScale + '.mat'\n",
    "\n",
    "    linkSet = scipy.io.loadmat(linksetFileLocation)['linkSet']\n",
    "    linkSet = linkSet-1\n",
    "    linkSet = linkSet.astype(int)\n",
    "\n",
    "    # save prepared data\n",
    "    baseFolder = '../gnnmodel'\n",
    "    baseName = baseFolder + '/data/' + caseName + '/' + 'load' + loadScale + 'gen' + loadScale + '/'\n",
    "    if not os.path.exists(baseFolder):\n",
    "        print('Base folder did not exist')\n",
    "    if not os.path.exists(baseName):\n",
    "        print('New data folder created')\n",
    "        os.makedirs(baseName)\n",
    "    print('Saved in folder ' + baseName)\n",
    "\n",
    "    np.save(baseName + 'nodeDataTrain', nodeDataTrain)\n",
    "    np.save(baseName + 'edgeDataTrain', edgeDataTrain)\n",
    "\n",
    "    np.save(baseName + 'nodeDataTest', nodeDataTest)\n",
    "    np.save(baseName + 'edgeDataTest', edgeDataTest)\n",
    "\n",
    "    np.save(baseName + 'linkSet', linkSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ecab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareInfluenceModelData():\n",
    "    # read influence data\n",
    "    influenceModelWeightFiles = dataDirectory + 'influenceModelParams.mat'\n",
    "    A01 = scipy.io.loadmat(influenceModelWeightFiles)['A01']\n",
    "    A11 = scipy.io.loadmat(influenceModelWeightFiles)['A11']\n",
    "    D = scipy.io.loadmat(influenceModelWeightFiles)['D']\n",
    "    epsilonVals = scipy.io.loadmat(influenceModelWeightFiles)['epsilonVals']\n",
    "    finalStates = scipy.io.loadmat(influenceModelWeightFiles)['finalStates']\n",
    "    initialStates = scipy.io.loadmat(influenceModelWeightFiles)['initialStates']\n",
    "\n",
    "    # save influence data\n",
    "    baseFolder = '../influencemodel'\n",
    "    baseName = baseFolder + '/data/' + caseName + '/' + 'load' + loadScale + 'gen' + loadScale + '/'\n",
    "    if not os.path.exists(baseFolder):\n",
    "        print('Base folder did not exist')\n",
    "    if not os.path.exists(baseName):\n",
    "        print('New data folder created')\n",
    "        os.makedirs(baseName)\n",
    "    print('Saved in folder ' + baseName)\n",
    "    \n",
    "    np.save(baseName + 'A01', A01)\n",
    "    np.save(baseName + 'A11', A11)\n",
    "    np.save(baseName + 'D', D)\n",
    "    np.save(baseName + 'epsilonVals', epsilonVals)\n",
    "    np.save(baseName + 'finalStates', finalStates)\n",
    "    np.save(baseName + 'initialStates', initialStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d9274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70f711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f51978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c319b63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510dadc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_chadaga)",
   "language": "python",
   "name": "env_chadaga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
